{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95ae7b86",
   "metadata": {},
   "source": [
    "# Machinery classification task\n",
    "\n",
    "The goal of this notebook will be to train a model to recogize the different type of machinery depending on the melspectrogram of audio sample. \n",
    "\n",
    "To do that we will use convolutionnal neural network CNN to extract features from the melspectrogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e805b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's first import the modules wee need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5e6325c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "PATH_FEATURES_FOLDER = './Features/'\n",
    "PATH_MELSPEC_313_128_FOLDER = PATH_FEATURES_FOLDER + 'melspec_313_128/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd36ae",
   "metadata": {},
   "source": [
    "## Train, validation, test dataset\n",
    "\n",
    "The spectrogram are stored in the folder Features/melspec_313_128/. Each machinery has its folder fan/, valve/ etc... <br />\n",
    "Each audio sample has its own mespectrogram flattened stored as a .npy file. So the file is one line of 313*128 = 40064 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e7963b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get file paths and labels\n",
    "path_files = []\n",
    "labels = []\n",
    "\n",
    "#Walk through melspectrogram folders\n",
    "for subdirectory, directory, files in os.walk(PATH_MELSPEC_313_128_FOLDER):\n",
    "    \n",
    "    #Get label using directory folder name\n",
    "    label = subdirectory.split('/')[-1]\n",
    "    \n",
    "    #Loop through files\n",
    "    for file in files:\n",
    "        path_file = subdirectory + '/' + file\n",
    "        path_files.append(path_file)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c1c2da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoded = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ca9617e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate into three datasets\n",
    "path_files_train, path_files_test, y_train, y_test = train_test_split(\n",
    "    path_files, label_encoded, test_size=0.1, stratify=label_encoded)\n",
    "\n",
    "path_files_train, path_files_valid, y_train, y_valid = train_test_split(\n",
    "    path_files_train, y_train, test_size=0.1, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7cc7b1",
   "metadata": {},
   "source": [
    "## Data Generator\n",
    "\n",
    "Since the datasets are quite big, let's make a data generator.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d06f607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(file_list, label_list, batch_size):\n",
    "    \n",
    "    #Index used too go over file list \n",
    "    index = 0\n",
    "    \n",
    "    #Infinite loop\n",
    "    while True:\n",
    "        \n",
    "        #Case we looped over all the files\n",
    "        if((index + 1) * batch_size >= len(file_list)):\n",
    "            #Reinit variables for a next round\n",
    "            index = 0\n",
    "            \n",
    "            #Shuffle list to have different batches\n",
    "            randomize = np.arange(len(file_list))\n",
    "            np.random.shuffle(randomize)\n",
    "            file_list = file_list[randomize]\n",
    "            label_list = label_list[randomize]\n",
    "            \n",
    "        #Loop over files from index * batch size to (index + 1) * batch size\n",
    "        else:\n",
    "            #Get files paths\n",
    "            file_chunk = file_list[index*batch_size:(index+1)*batch_size]\n",
    "            label_chunk = label_list[index*batch_size:(index+1)*batch_size]\n",
    "            \n",
    "            #Init data and labels list\n",
    "            data = []\n",
    "            labels = []\n",
    "            \n",
    "            #Loop over batch files\n",
    "            for file, label in zip(file_chunk, label_chunk):\n",
    "                data.append(np.load(file).reshape(128, 313, 1))\n",
    "                labels.append(tf.keras.utils.to_categorical(label, num_classes=7))\n",
    "                \n",
    "            data = np.asarray(data)\n",
    "            labels = np.asarray(labels)\n",
    "            yield data, labels\n",
    "            index = index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92be423",
   "metadata": {},
   "source": [
    "Let's use the Dataset tensorflow class based on those generators to create train, valid and test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c689687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator,\n",
    "    args= [path_files_train, y_train, batch_size],\n",
    "    output_types = (tf.float32, tf.float32),\n",
    "    output_shapes = ((batch_size, 128, 313, 1),(batch_size, 7))\n",
    ")\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator,\n",
    "    args= [path_files_valid, y_valid, batch_size],\n",
    "    output_types = (tf.float32, tf.float32),\n",
    "    output_shapes = ((batch_size, 128, 313, 1),(batch_size, 7))\n",
    ")\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator,\n",
    "    args= [path_files_test, y_test, batch_size],\n",
    "    output_types = (tf.float32, tf.float32),\n",
    "    output_shapes = ((batch_size, 128, 313, 1),(batch_size, 7))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007ccd9",
   "metadata": {},
   "source": [
    "## CNN Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b715ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create layers of CNN\n",
    "inputs = Input(shape = (128, 313, 1), name = \"Input\")\n",
    "first_layer = Conv2D(filters = 32,\n",
    "                     kernel_size = (5, 5),\n",
    "                     padding = 'valid',\n",
    "                     activation = 'relu')\n",
    "second_layer = MaxPooling2D(pool_size = (2, 2))\n",
    "third_layer = Dropout(rate=0.2)\n",
    "fourth_layer = Flatten()\n",
    "fifth_layer = Dense(128, activation='relu')\n",
    "output_layer = Dense(7, activation='softmax')\n",
    "\n",
    "#Organize them\n",
    "x=first_layer(inputs)\n",
    "x=second_layer(x)\n",
    "x = third_layer(x)\n",
    "x = fourth_layer(x)\n",
    "x = fifth_layer(x)\n",
    "outputs = output_layer(x)\n",
    "\n",
    "#create model and compile\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ffba4",
   "metadata": {},
   "source": [
    "## Train CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e5431f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch =  638\n",
      "validation_steps =  71\n"
     ]
    }
   ],
   "source": [
    "#Get steps per epoch\n",
    "steps_per_epoch = np.int32(np.ceil(len(path_files_train)/batch_size))\n",
    "validation_steps = np.int32(np.ceil(len(path_files_valid)/batch_size))\n",
    "print(\"steps_per_epoch = \", steps_per_epoch)\n",
    "print(\"validation_steps = \", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "634c33e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "638/638 [==============================] - 403s 630ms/step - loss: 26.4719 - accuracy: 0.8789 - val_loss: 0.1492 - val_accuracy: 0.9551\n",
      "Epoch 2/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0921 - accuracy: 0.9683 - val_loss: 0.1196 - val_accuracy: 0.9652\n",
      "Epoch 3/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0647 - accuracy: 0.9794 - val_loss: 0.0879 - val_accuracy: 0.9767\n",
      "Epoch 4/100\n",
      "638/638 [==============================] - 28s 43ms/step - loss: 0.0563 - accuracy: 0.9816 - val_loss: 0.1834 - val_accuracy: 0.9529\n",
      "Epoch 5/100\n",
      "638/638 [==============================] - 28s 43ms/step - loss: 0.0505 - accuracy: 0.9845 - val_loss: 0.2631 - val_accuracy: 0.9322\n",
      "Epoch 6/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.1354 - accuracy: 0.9562 - val_loss: 0.2665 - val_accuracy: 0.9186\n",
      "Epoch 7/100\n",
      "638/638 [==============================] - 27s 43ms/step - loss: 0.0619 - accuracy: 0.9808 - val_loss: 0.1215 - val_accuracy: 0.9621\n",
      "Epoch 8/100\n",
      "638/638 [==============================] - 28s 43ms/step - loss: 0.0263 - accuracy: 0.9917 - val_loss: 0.1413 - val_accuracy: 0.9604\n",
      "Epoch 9/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0743 - val_accuracy: 0.9815\n",
      "Epoch 10/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0640 - accuracy: 0.9816 - val_loss: 0.1037 - val_accuracy: 0.9710\n",
      "Epoch 11/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.1038 - accuracy: 0.9768 - val_loss: 0.4367 - val_accuracy: 0.8653\n",
      "Epoch 12/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0475 - accuracy: 0.9858 - val_loss: 0.1477 - val_accuracy: 0.9762\n",
      "Epoch 13/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0699 - accuracy: 0.9774 - val_loss: 0.2933 - val_accuracy: 0.9142\n",
      "Epoch 14/100\n",
      "638/638 [==============================] - 28s 43ms/step - loss: 0.1183 - accuracy: 0.9603 - val_loss: 0.1088 - val_accuracy: 0.9621\n",
      "Epoch 15/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0559 - accuracy: 0.9819 - val_loss: 0.1588 - val_accuracy: 0.9595\n",
      "Epoch 16/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.1349 - accuracy: 0.9684 - val_loss: 0.1131 - val_accuracy: 0.9683\n",
      "Epoch 17/100\n",
      "638/638 [==============================] - 29s 45ms/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 0.1103 - val_accuracy: 0.9802\n",
      "Epoch 18/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0245 - accuracy: 0.9952 - val_loss: 0.7935 - val_accuracy: 0.9124\n",
      "Epoch 19/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0535 - accuracy: 0.9854 - val_loss: 0.1540 - val_accuracy: 0.9723\n",
      "Epoch 20/100\n",
      "638/638 [==============================] - 28s 43ms/step - loss: 0.0425 - accuracy: 0.9871 - val_loss: 0.1129 - val_accuracy: 0.9679\n",
      "Epoch 21/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0278 - accuracy: 0.9904 - val_loss: 0.1166 - val_accuracy: 0.9679\n",
      "Epoch 22/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0306 - accuracy: 0.9908 - val_loss: 0.1712 - val_accuracy: 0.9692\n",
      "Epoch 23/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0253 - accuracy: 0.9925 - val_loss: 0.1875 - val_accuracy: 0.9652\n",
      "Epoch 24/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0855 - accuracy: 0.9814 - val_loss: 0.1190 - val_accuracy: 0.9705\n",
      "Epoch 25/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0219 - accuracy: 0.9935 - val_loss: 0.1204 - val_accuracy: 0.9736\n",
      "Epoch 26/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.1526 - val_accuracy: 0.9679\n",
      "Epoch 27/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.1231 - val_accuracy: 0.9784\n",
      "Epoch 28/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0354 - accuracy: 0.9902 - val_loss: 0.1985 - val_accuracy: 0.9727\n",
      "Epoch 29/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0410 - accuracy: 0.9920 - val_loss: 0.1614 - val_accuracy: 0.9688\n",
      "Epoch 30/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0163 - accuracy: 0.9955 - val_loss: 0.1761 - val_accuracy: 0.9692\n",
      "Epoch 31/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0456 - accuracy: 0.9904 - val_loss: 0.1202 - val_accuracy: 0.9815\n",
      "Epoch 32/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0137 - accuracy: 0.9971 - val_loss: 0.3264 - val_accuracy: 0.9463\n",
      "Epoch 33/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.1784 - val_accuracy: 0.9745\n",
      "Epoch 34/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.1160 - val_accuracy: 0.9811\n",
      "Epoch 35/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0255 - accuracy: 0.9935 - val_loss: 0.2048 - val_accuracy: 0.9661\n",
      "Epoch 36/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0238 - accuracy: 0.9934 - val_loss: 0.3089 - val_accuracy: 0.9586\n",
      "Epoch 37/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1303 - val_accuracy: 0.9780\n",
      "Epoch 38/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0274 - accuracy: 0.9931 - val_loss: 0.1574 - val_accuracy: 0.9740\n",
      "Epoch 39/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0110 - accuracy: 0.9972 - val_loss: 0.1545 - val_accuracy: 0.9758\n",
      "Epoch 40/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.1265 - val_accuracy: 0.9806\n",
      "Epoch 41/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0196 - accuracy: 0.9954 - val_loss: 0.1181 - val_accuracy: 0.9811\n",
      "Epoch 42/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0186 - accuracy: 0.9961 - val_loss: 0.1409 - val_accuracy: 0.9784\n",
      "Epoch 43/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0202 - accuracy: 0.9950 - val_loss: 0.2567 - val_accuracy: 0.9573\n",
      "Epoch 44/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0163 - accuracy: 0.9959 - val_loss: 0.1721 - val_accuracy: 0.9784\n",
      "Epoch 45/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.1363 - val_accuracy: 0.9798\n",
      "Epoch 46/100\n",
      "638/638 [==============================] - 28s 43ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.1771 - val_accuracy: 0.9771\n",
      "Epoch 47/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0163 - accuracy: 0.9955 - val_loss: 0.2455 - val_accuracy: 0.9617\n",
      "Epoch 48/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0132 - accuracy: 0.9975 - val_loss: 0.2214 - val_accuracy: 0.9657\n",
      "Epoch 49/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0198 - accuracy: 0.9954 - val_loss: 0.3424 - val_accuracy: 0.9454\n",
      "Epoch 50/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0115 - accuracy: 0.9977 - val_loss: 0.2114 - val_accuracy: 0.9732\n",
      "Epoch 51/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.2025 - accuracy: 0.9832 - val_loss: 0.3043 - val_accuracy: 0.9621\n",
      "Epoch 52/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.2241 - val_accuracy: 0.9745\n",
      "Epoch 53/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.2568 - val_accuracy: 0.9740\n",
      "Epoch 54/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.1954 - val_accuracy: 0.9784\n",
      "Epoch 55/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.2280 - val_accuracy: 0.9776\n",
      "Epoch 56/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0094 - accuracy: 0.9986 - val_loss: 0.4224 - val_accuracy: 0.9533\n",
      "Epoch 57/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0105 - accuracy: 0.9981 - val_loss: 0.2723 - val_accuracy: 0.9754\n",
      "Epoch 58/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0158 - accuracy: 0.9971 - val_loss: 0.1969 - val_accuracy: 0.9806\n",
      "Epoch 59/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.3890 - val_accuracy: 0.9657\n",
      "Epoch 60/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0128 - accuracy: 0.9972 - val_loss: 0.3325 - val_accuracy: 0.9758\n",
      "Epoch 61/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.2256 - val_accuracy: 0.9776\n",
      "Epoch 62/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0153 - accuracy: 0.9972 - val_loss: 0.2730 - val_accuracy: 0.9767\n",
      "Epoch 63/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0277 - accuracy: 0.9956 - val_loss: 0.1817 - val_accuracy: 0.9771\n",
      "Epoch 64/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.1683 - val_accuracy: 0.9736\n",
      "Epoch 65/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0372 - accuracy: 0.9931 - val_loss: 0.2209 - val_accuracy: 0.9696\n",
      "Epoch 66/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 0.2326 - val_accuracy: 0.9705\n",
      "Epoch 67/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0165 - accuracy: 0.9966 - val_loss: 0.2360 - val_accuracy: 0.9758\n",
      "Epoch 68/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0133 - accuracy: 0.9976 - val_loss: 0.2091 - val_accuracy: 0.9811\n",
      "Epoch 69/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.2419 - val_accuracy: 0.9767\n",
      "Epoch 70/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0200 - accuracy: 0.9969 - val_loss: 0.4407 - val_accuracy: 0.9652\n",
      "Epoch 71/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.2336 - val_accuracy: 0.9789\n",
      "Epoch 72/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.2552 - val_accuracy: 0.9696\n",
      "Epoch 73/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0337 - accuracy: 0.9936 - val_loss: 0.2805 - val_accuracy: 0.9723\n",
      "Epoch 74/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.2831 - val_accuracy: 0.9714\n",
      "Epoch 75/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0103 - accuracy: 0.9984 - val_loss: 0.2185 - val_accuracy: 0.9793\n",
      "Epoch 76/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0274 - accuracy: 0.9953 - val_loss: 0.3275 - val_accuracy: 0.9758\n",
      "Epoch 77/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.3640 - val_accuracy: 0.9626\n",
      "Epoch 78/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.2296 - val_accuracy: 0.9740\n",
      "Epoch 79/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.1789 - val_accuracy: 0.9811\n",
      "Epoch 80/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.2724 - val_accuracy: 0.9727\n",
      "Epoch 81/100\n",
      "638/638 [==============================] - 28s 45ms/step - loss: 0.0164 - accuracy: 0.9964 - val_loss: 0.2608 - val_accuracy: 0.9784\n",
      "Epoch 82/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0370 - accuracy: 0.9947 - val_loss: 0.3119 - val_accuracy: 0.9749\n",
      "Epoch 83/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.2625 - val_accuracy: 0.9767\n",
      "Epoch 84/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.3037 - val_accuracy: 0.9692\n",
      "Epoch 85/100\n",
      "638/638 [==============================] - 28s 45ms/step - loss: 0.0270 - accuracy: 0.9949 - val_loss: 0.5629 - val_accuracy: 0.9617\n",
      "Epoch 86/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.2917 - val_accuracy: 0.9767\n",
      "Epoch 87/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0175 - accuracy: 0.9976 - val_loss: 0.3218 - val_accuracy: 0.9604\n",
      "Epoch 88/100\n",
      "638/638 [==============================] - 28s 45ms/step - loss: 0.0157 - accuracy: 0.9976 - val_loss: 0.2749 - val_accuracy: 0.9736\n",
      "Epoch 89/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.2640 - val_accuracy: 0.9718\n",
      "Epoch 90/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.2780 - val_accuracy: 0.9824\n",
      "Epoch 91/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0470 - accuracy: 0.9936 - val_loss: 0.4095 - val_accuracy: 0.9718\n",
      "Epoch 92/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.4661 - val_accuracy: 0.9657\n",
      "Epoch 93/100\n",
      "638/638 [==============================] - 29s 45ms/step - loss: 0.0077 - accuracy: 0.9989 - val_loss: 0.6026 - val_accuracy: 0.9591\n",
      "Epoch 94/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.1108 - accuracy: 0.9813 - val_loss: 0.3872 - val_accuracy: 0.9657\n",
      "Epoch 95/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.2943 - val_accuracy: 0.9749\n",
      "Epoch 96/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 4.2504e-04 - accuracy: 0.9999 - val_loss: 0.2654 - val_accuracy: 0.9754\n",
      "Epoch 97/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0107 - accuracy: 0.9986 - val_loss: 0.2717 - val_accuracy: 0.9784\n",
      "Epoch 98/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.2546 - val_accuracy: 0.9811\n",
      "Epoch 99/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0125 - accuracy: 0.9979 - val_loss: 0.3886 - val_accuracy: 0.9705\n",
      "Epoch 100/100\n",
      "638/638 [==============================] - 28s 44ms/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 0.2818 - val_accuracy: 0.9767\n"
     ]
    }
   ],
   "source": [
    "training_history = model.fit(train_dataset, validation_data = validation_dataset, steps_per_epoch = steps_per_epoch,\n",
    "         validation_steps = validation_steps, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0922f1",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a9db93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot training\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(np.arange(1 , len(trainin_history.history['accuracy']) + 1, 1),\n",
    "         trainin_history.history['accuracy'],\n",
    "         label = 'Training Accuracy',\n",
    "         color = 'blue')\n",
    "plt.plot(np.arange(1 , len(trainin_history.history['val_accuracy']) + 1, 1),\n",
    "         trainin_history.history['val_accuracy'], \n",
    "         label = 'Validation Accuracy',\n",
    "         color = 'red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8903a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get prediction\n",
    "test_pred = model.predict(test_dataset)\n",
    "\n",
    "#Get class prediction\n",
    "test_pred_class = np.argmax(test_pred, axis=1)\n",
    "y_test_class = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29973ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate model\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_class, test_pred_class))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(y_test_class, test_pred_class)\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2be9d1",
   "metadata": {},
   "source": [
    "# More complex model\n",
    "\n",
    "Inspired by VGG-16.\n",
    "\n",
    "Input: 128x313 <br/>\n",
    "Conv2D (3*3) pad=1, filters 64, ((128-3+2*1)+1) * ((313-3+2*1)+1) * 64 => 128 * 313 * 64 <br/>\n",
    "Conv2D (3*3) pad=1, filters 64, ((128-3+2*1)+1) * ((313-3+2*1)+1) * 64 => 128 * 313 * 64 <br/>\n",
    "MaxPool2D (3*3), stride = 2, ((128-3)/2 + 1) * ((313-3)/2 + 1) * 64 => 64 * 156 * 64\n",
    "\n",
    "Conv2D (3*3) pad=1, filters 128 ((64-3+2*1)+1) * ((156-3+2*1)+1) * 128 => 64 * 156 * 128 <br/>\n",
    "Conv2D (3*3) pad=1, filters 128 ((64-3+2*1)+1) * ((156-3+2*1)+1) * 128 => 64 * 156 * 128 <br/>\n",
    "MaxPool2D (3*3), stride = 2, ((64-3)/2 + 1) * ((156-3)/2 + 1) * 128 => 32 * 78 * 128\n",
    "\n",
    "Conv2D (3*3) pad=1, filters 256 ((32-3+2*1)+1) * ((78-3+2*1)+1) * 256 => 32 * 78 * 256 <br/>\n",
    "Conv2D (3*3) pad=1, filters 256 ((32-3+2*1)+1) * ((78-3+2*1)+1) * 256 => 32 * 78 * 256 <br/>\n",
    "Conv2D (3*3) pad=1, filters 256 ((32-3+2*1)+1) * ((78-3+2*1)+1) * 256 => 32 * 78 * 256 <br/>\n",
    "MaxPool2D (3*3), stride = 2, ((32-3)/2 + 1) * ((78-3)/2 + 1) * 256 => 16 * 39 * 256\n",
    "\n",
    "Conv2D (3*3) pad=1, filters 512 ((16-3+2*1)+1) * ((39-3+2*1)+1) * 512 => 16 * 39 * 512 <br/>\n",
    "Conv2D (3*3) pad=1, filters 512 ((16-3+2*1)+1) * ((39-3+2*1)+1) * 512 => 16 * 39 * 512 <br/>\n",
    "Conv2D (3*3) pad=1, filters 512 ((16-3+2*1)+1) * ((39-3+2*1)+1) * 512 => 16 * 39 * 512 <br/>\n",
    "MaxPool2D (3*3), stride = 2, ((16-3)/2 + 1) * ((39-3)/2 + 1) * 512 => 8 * 19 * 512\n",
    "\n",
    "Flatten => 77824 <br/>\n",
    "Dense (4096), activation=relu => 4096 <br/>\n",
    "Dropout (0.2)\n",
    "\n",
    "Dense (4096), activation=relu => 4096 <br/>\n",
    "Dropout (0.2)\n",
    "\n",
    "Dense (7), activation=softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b8cda448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create layers of CNN\n",
    "inputs = Input(shape = (128, 313, 1), name = \"Input\")\n",
    "normalize = BatchNormalization(axis=2)\n",
    "conv_1_1 = Conv2D(filters = 64,\n",
    "                     kernel_size = (3, 3),\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu')\n",
    "conv_1_2 = Conv2D(filters = 64,\n",
    "                     kernel_size = (3, 3),\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu')\n",
    "pool_1_3 = MaxPooling2D(pool_size = (3, 3), strides=(2,2))\n",
    "\n",
    "x = normalize(inputs)\n",
    "x = conv_1_1(x)\n",
    "x = conv_1_2(x)\n",
    "x = pool_1_3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d8759285",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_2_1 = Conv2D(filters = 128,\n",
    "                     kernel_size = (3, 3),\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu')\n",
    "conv_2_2 = Conv2D(filters = 128,\n",
    "                     kernel_size = (3, 3),\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu')\n",
    "pool_2_3 = MaxPooling2D(pool_size = (3, 3), strides=(2,2))\n",
    "\n",
    "x = conv_2_1(x)\n",
    "x = conv_2_2(x)\n",
    "x = pool_2_3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fda0b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3_1 = Conv2D(filters = 256,\n",
    "                     kernel_size = (3, 3),\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu')\n",
    "conv_3_2 = Conv2D(filters = 256,\n",
    "                     kernel_size = (3, 3),\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu')\n",
    "conv_3_3 = Conv2D(filters = 256,\n",
    "                     kernel_size = (3, 3),\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu')\n",
    "pool_3_4 = MaxPooling2D(pool_size = (3, 3), strides=(2,2))\n",
    "\n",
    "x = conv_3_1(x)\n",
    "x = conv_3_2(x)\n",
    "x = conv_3_3(x)\n",
    "x = pool_3_4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fc512e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_4_1 = Conv2D(filters = 512,\n",
    "                     kernel_size = (3, 3),\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu')\n",
    "conv_4_2 = Conv2D(filters = 512,\n",
    "                     kernel_size = (3, 3),\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu')\n",
    "conv_4_3 = Conv2D(filters = 512,\n",
    "                     kernel_size = (3, 3),\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu')\n",
    "pool_4_4 = MaxPooling2D(pool_size = (3, 3), strides=(2,2))\n",
    "\n",
    "x = conv_4_1(x)\n",
    "x = conv_4_2(x)\n",
    "x = conv_4_3(x)\n",
    "x = pool_4_4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7bfa9e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_5_1 = Flatten()\n",
    "dense_5_2 = Dense(4096, activation='relu')\n",
    "drop_5_3 = Dropout(rate=0.2)\n",
    "dense_5_4 = Dense(4096, activation='relu')\n",
    "drop_5_5 = Dropout(rate=0.2)\n",
    "out_5_6 = Dense(7, activation='softmax')\n",
    "\n",
    "x = flat_5_1(x)\n",
    "x = dense_5_2(x)\n",
    "x = drop_5_3(x)\n",
    "x = dense_5_4(x)\n",
    "x = drop_5_5(x)\n",
    "outputs = out_5_6(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ffd413",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "73e7820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model and compile\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "04428b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 128, 313, 1)]     0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128, 313, 1)      1252      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 128, 313, 64)      640       \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 128, 313, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 63, 156, 64)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 63, 156, 128)      73856     \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 63, 156, 128)      147584    \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 31, 77, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 31, 77, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 31, 77, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 31, 77, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 15, 38, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 15, 38, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 15, 38, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 15, 38, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 7, 18, 512)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 64512)             0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4096)              264245248 \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 7)                 28679     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 288,690,603\n",
      "Trainable params: 288,689,977\n",
      "Non-trainable params: 626\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0bf678",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e1dca9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch =  638\n",
      "validation_steps =  71\n"
     ]
    }
   ],
   "source": [
    "#Get steps per epoch\n",
    "steps_per_epoch = np.int32(np.ceil(len(path_files_train)/batch_size))\n",
    "validation_steps = np.int32(np.ceil(len(path_files_valid)/batch_size))\n",
    "print(\"steps_per_epoch = \", steps_per_epoch)\n",
    "print(\"validation_steps = \", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1e5f29fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "638/638 [==============================] - 213s 332ms/step - loss: 2.0036 - accuracy: 0.1466 - val_loss: 1.9460 - val_accuracy: 0.1413\n",
      "Epoch 2/100\n",
      "638/638 [==============================] - 211s 331ms/step - loss: 1.9463 - accuracy: 0.1390 - val_loss: 1.9460 - val_accuracy: 0.1439\n",
      "Epoch 3/100\n",
      "638/638 [==============================] - 211s 331ms/step - loss: 1.9462 - accuracy: 0.1375 - val_loss: 1.9459 - val_accuracy: 0.1439\n",
      "Epoch 4/100\n",
      "638/638 [==============================] - 211s 331ms/step - loss: 1.9462 - accuracy: 0.1341 - val_loss: 1.9459 - val_accuracy: 0.1444\n",
      "Epoch 5/100\n",
      "638/638 [==============================] - 211s 331ms/step - loss: 1.9461 - accuracy: 0.1396 - val_loss: 1.9459 - val_accuracy: 0.1430\n",
      "Epoch 6/100\n",
      "638/638 [==============================] - 211s 331ms/step - loss: 1.9461 - accuracy: 0.1401 - val_loss: 1.9459 - val_accuracy: 0.1435\n",
      "Epoch 7/100\n",
      "638/638 [==============================] - 211s 331ms/step - loss: 1.9461 - accuracy: 0.1374 - val_loss: 1.9459 - val_accuracy: 0.1444\n",
      "Epoch 8/100\n",
      "638/638 [==============================] - 211s 331ms/step - loss: 1.9461 - accuracy: 0.1394 - val_loss: 1.9459 - val_accuracy: 0.1439\n",
      "Epoch 9/100\n",
      "638/638 [==============================] - 211s 331ms/step - loss: 1.9461 - accuracy: 0.1400 - val_loss: 1.9459 - val_accuracy: 0.1430\n",
      "Epoch 10/100\n",
      "638/638 [==============================] - 211s 331ms/step - loss: 1.9461 - accuracy: 0.1396 - val_loss: 1.9459 - val_accuracy: 0.1430\n",
      "Epoch 11/100\n",
      "269/638 [===========>..................] - ETA: 1:58 - loss: 1.9461 - accuracy: 0.1425"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [167]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m training_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m         \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow_keras\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow_keras\\lib\\site-packages\\keras\\engine\\training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1387\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1388\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1389\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1391\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow_keras\\lib\\site-packages\\keras\\callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \n\u001b[0;32m    433\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 438\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow_keras\\lib\\site-packages\\keras\\callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    295\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 297\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    300\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow_keras\\lib\\site-packages\\keras\\callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    316\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    321\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow_keras\\lib\\site-packages\\keras\\callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    355\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    359\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow_keras\\lib\\site-packages\\keras\\callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1034\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow_keras\\lib\\site-packages\\keras\\callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1105\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1106\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1107\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow_keras\\lib\\site-packages\\keras\\utils\\tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    561\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow_keras\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow_keras\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow_keras\\lib\\site-packages\\keras\\utils\\tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    555\u001b[0m   \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    556\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 557\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m   \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow_keras\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \n\u001b[0;32m   1202\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1223\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow_keras\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1188\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1190\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_history = model.fit(train_dataset, validation_data = validation_dataset, steps_per_epoch = steps_per_epoch,\n",
    "         validation_steps = validation_steps, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c5ab95",
   "metadata": {},
   "source": [
    "a ne fonctionne pas du tout. Pourquoi?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb3061a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
